{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4409343",
   "metadata": {},
   "source": [
    "# Installation of Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2acc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install Transformers\n",
    "!pip install transformers==3\n",
    "# To get model summary\n",
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4027de39",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a191d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "import matplotlib.pyplot as plt\n",
    "# specify GPU\n",
    "device = torch.device(“cuda”)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9013217e",
   "metadata": {},
   "source": [
    "# Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a24e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have prepared a chitchat dataset with 5 labels\n",
    "df = pd.read_excel(“/content/drive/MyDrive/Datasets/chitchat.xlsx”)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f1f10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[‘label’].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ff4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the labels into encodings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "# check class distribution\n",
    "df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3c4adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example we have used all the utterances for training purpose\n",
    "train_text, train_labels = df[‘text’], df[‘label’]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2719b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prepration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36645b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT Model\n",
    "# We can import the Bert model as below.\n",
    "\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(‘bert-base-uncased’)\n",
    "# Import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained(‘bert-base-uncased’)\n",
    "\n",
    "\n",
    "# Roberta Model\n",
    "# We can import the Roberta model as below.\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "# Load the Roberta tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(‘roberta-base’)\n",
    "# Import Roberta pretrained model\n",
    "bert = RobertaModel.from_pretrained(‘roberta-base’)\n",
    "\n",
    "\n",
    "# DistilBert Model\n",
    "# We can import the DistilBert model as below.\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "# Load the DistilBert tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(‘distilbert-base-uncased’)\n",
    "# Import the DistilBert pretrained model\n",
    "bert = DistilBertModel.from_pretrained(“distilbert-base-uncased”)\n",
    "\n",
    "\n",
    "# We will be using DistilBert model for this example.\n",
    "\n",
    "# Sample data for distilbert-base-uncased tokenizer\n",
    "\n",
    "text = [\"this is a distil bert model.\",\"data is oil\"]\n",
    "# Encode the text\n",
    "encoded_input = tokenizer(text, padding=True,truncation=True, return_tensors='pt')\n",
    "print(encoded_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da389204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in train_text]\n",
    "pd.Series(seq_len).hist(bins = 10)\n",
    "# Based on the histogram we are selecting the max len as 8\n",
    "max_seq_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8c42d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "tokens_train = tokenizer(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6810fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104318c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#define a batch size\n",
    "batch_size = 16\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# DataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f1934",
   "metadata": {},
   "source": [
    "## Define Model Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae27c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "   def __init__(self, bert):      \n",
    "       super(BERT_Arch, self).__init__()\n",
    "       self.bert = bert \n",
    "      \n",
    "       # dropout layer\n",
    "       self.dropout = nn.Dropout(0.2)\n",
    "      \n",
    "       # relu activation function\n",
    "       self.relu =  nn.ReLU()\n",
    "       # dense layer\n",
    "       self.fc1 = nn.Linear(768,512)\n",
    "       self.fc2 = nn.Linear(512,256)\n",
    "       self.fc3 = nn.Linear(256,5)\n",
    "       #softmax activation function\n",
    "       self.softmax = nn.LogSoftmax(dim=1)\n",
    "       #define the forward pass\n",
    "   def forward(self, sent_id, mask):\n",
    "      #pass the inputs to the model  \n",
    "      cls_hs = self.bert(sent_id, attention_mask=mask)[0][:,0]\n",
    "      \n",
    "      x = self.fc1(cls_hs)\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      \n",
    "      x = self.fc2(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.dropout(x)\n",
    "      # output layer\n",
    "      x = self.fc3(x)\n",
    "   \n",
    "      # apply softmax activation\n",
    "      x = self.softmax(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a711c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters. This will prevent updating of model weights during fine-tuning.\n",
    "for param in bert.parameters():\n",
    "      param.requires_grad = False\n",
    "model = BERT_Arch(bert)\n",
    "# push the model to GPU\n",
    "model = model.to(device)\n",
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648dc2b5",
   "metadata": {},
   "source": [
    "# Fine Tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ba513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "# Using the Optimizer we reduce the loss during backpropagation through the network.\n",
    "\n",
    "from transformers import AdamW\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Class Weights\n",
    "\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight(‘balanced’, np.unique(train_labels), train_labels)\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c9a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the weights while calculating the error\n",
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "# loss function\n",
    "cross_entropy = nn.NLLLoss(weight=weights) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Setting up the epochs\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "\n",
    "train_losses=[]\n",
    "# number of training epochs\n",
    "epochs = 200\n",
    "# We can also use learning rate scheduler to achieve better results\n",
    "lr_sch = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b4813a",
   "metadata": {},
   "source": [
    "## Fine-Tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2657732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "  \n",
    "  model.train()\n",
    "  total_loss = 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print('  Batch {:>5,}  of  {:>5,}.'.format(step,    len(train_dataloader)))\n",
    "    # push the batch to gpu\n",
    "    batch = [r.to(device) for r in batch] \n",
    "    sent_id, mask, labels = batch\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "    # compute the loss between actual and predicted values\n",
    "    loss = cross_entropy(preds, labels)\n",
    "    # add on to the total loss\n",
    "    total_loss = total_loss + loss.item()\n",
    "    # backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "    # clip the the gradients to 1.0. It helps in preventing the    exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "    # clear calculated gradients\n",
    "    optimizer.zero_grad()\n",
    "  \n",
    "    # We are not using learning rate scheduler as of now\n",
    "    # lr_sch.step()\n",
    "    # model predictions are stored on GPU. So, push it to CPU\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "    # append the model predictions\n",
    "    total_preds.append(preds)\n",
    "# compute the training loss of the epoch\n",
    "avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "# predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "# reshape the predictions in form of (number of samples, no. of classes)\n",
    "total_preds  = np.concatenate(total_preds, axis=0)\n",
    "#returns the loss and predictions\n",
    "return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2665414",
   "metadata": {},
   "source": [
    "## Start Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d891946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    # it can make your experiment reproducible, similar to set  random seed to all options where there needs a random seed.\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "print(f'\\nTraining Loss: {train_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2532cd9",
   "metadata": {},
   "source": [
    "## Get Predictions for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f24d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(str):\n",
    " str = re.sub(r’[^a-zA-Z ]+’, ‘’, str)\n",
    " test_text = [str]\n",
    " model.eval()\n",
    " \n",
    " tokens_test_data = tokenizer(\n",
    " test_text,\n",
    " max_length = max_seq_len,\n",
    " pad_to_max_length=True,\n",
    " truncation=True,\n",
    " return_token_type_ids=False\n",
    " )\n",
    " test_seq = torch.tensor(tokens_test_data[‘input_ids’])\n",
    " test_mask = torch.tensor(tokens_test_data[‘attention_mask’])\n",
    " \n",
    " preds = None\n",
    " with torch.no_grad():\n",
    "   preds = model(test_seq.to(device), test_mask.to(device))\n",
    " preds = preds.detach().cpu().numpy()\n",
    " preds = np.argmax(preds, axis = 1)\n",
    " print(“Intent Identified: “, le.inverse_transform(preds)[0])\n",
    " return le.inverse_transform(preds)[0]\n",
    "def get_response(message): \n",
    "  intent = get_prediction(message)\n",
    "  for i in data['intents']: \n",
    "    if i[\"tag\"] == intent:\n",
    "      result = random.choice(i[\"responses\"])\n",
    "      break\n",
    "  print(f\"Response : {result}\")\n",
    "  return \"Intent: \"+ intent + '\\n' + \"Response: \" + result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84341ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response(“why dont you introduce yourself”)"
   ]
  },
  {
   "attachments": {
    "1_EvGwOPyZX0v0XdJLVaRukQ.webp": {
     "image/webp": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5583fcb2",
   "metadata": {},
   "source": [
    "![1_EvGwOPyZX0v0XdJLVaRukQ.webp](attachment:1_EvGwOPyZX0v0XdJLVaRukQ.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43e9fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo-venv",
   "language": "python",
   "name": "demo-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
